# Docify Unified Orchestrator v3.0

A **simplified, safe, and reliable** document analysis function that preserves raw content, generates AI-powered titles, and maintains full compatibility with your existing `docify-website`. This is the unified replacement for the old `llm-analyzer-python` and `document-scraper-python` functions.

## üéØ **Core Innovation**

This function provides a **simplified, safe approach** to document analysis:

### **üîí Raw Content Preservation**
- **No Dangerous Cleaning**: Saves browserless content exactly as received
- **Complete Transparency**: You can always see what was actually scraped
- **Reliable Storage**: Raw HTML preserved in `scraped_content` field

### **ü§ñ AI-Powered Intelligence**
- **Smart Titles**: Generates 2-4 word titles using Gemini 2.5 Flash AI with HTML fallback
- **HTML Title Extraction**: Automatically extracts titles from scraped content when AI fails
- **Comprehensive Summaries**: Detailed, instruction-specific summaries up to 5000 characters
- **Compatible Blocks**: Exact same JSON format as your existing `llm-analyzer-python`

### **üéØ 8-Step Linear Process**
- **Step 1**: Extract document data from trigger
- **Step 2**: Validate environment and API keys
- **Step 3**: Raw browserless content scraping (no modification)
- **Step 4**: Save raw content to database immediately
- **Step 5**: Generate AI-powered 2-4 word title (with HTML fallback)
- **Step 6**: Create comprehensive analysis using Gemini with instruction-specific summaries
- **Step 7**: Format blocks with 2√ó3 grid layout validation and syntax checking
- **Step 8**: Final save and mark as completed

### **üìê Grid Layout System**
- **Layout**: 2 rows √ó 3 columns = 6 total cells
- **Block Heights**: All blocks are 1 row tall (2 rows maximum)
- **Size Options**:
  - **Small**: 1√ó1 cell (fits anywhere)
  - **Medium**: 2√ó1 cells (spans 2 columns, max 2 per row)
  - **Large**: 3√ó2 cells (fills entire grid, use only when necessary)
- **Constraints**: Maximum 2 medium blocks, maximum 6 small blocks
- **Validation**: Automatic grid overflow prevention and syntax checking

### **üõ°Ô∏è Safety & Compatibility**
- **Zero Data Loss**: Raw content never modified or cleaned
- **100% Compatible**: Same JSON format as existing analyzer
- **Simple Tracking**: Clear tools usage and research context
- **Error Recovery**: Graceful fallbacks at each step
- **Syntax Validation**: Ensures proper mermaid/code/key_points block formatting
- **Content Standards**: Enforces formatting requirements for all block types

## üèóÔ∏è **Architecture**

### **Single-File Structure (Simplified)**
```
docify-unified-orchestrator/
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îî‚îÄ‚îÄ main.py                    # Single file with 8 clear functions
‚îú‚îÄ‚îÄ requirements.txt
‚îú‚îÄ‚îÄ package.json
‚îî‚îÄ‚îÄ README.md
```

### **8-Step Processing Functions**
- `extract_document_data()` - Step 1: Get document info from trigger
- `validate_environment()` - Step 2: Check API keys and setup
- `scrape_raw_content()` - Step 3: Browserless scraping (no cleaning)
- `save_raw_content()` - Step 4: Save raw HTML to database
- `generate_ai_title()` - Step 5: AI-powered 2-4 word title
- `generate_analysis()` - Step 6: Gemini analysis with same prompt
- `create_compatible_blocks()` - Step 7: Format blocks like llm-analyzer-python
- `final_save_and_complete()` - Step 8: Save results and mark completed

## üöÄ **Key Features**

### **üîí Safe Content Handling**
- **Raw Content Only**: Never modifies or cleans scraped content
- **Complete Transparency**: You can always see exactly what was scraped
- **Browserless Integration**: Uses same scraping approach as document-scraper-python
- **No Data Loss**: Raw HTML preserved exactly as received

### **ü§ñ AI-Powered Analysis**
- **Smart Title Generation**: 2-4 word titles generated by Gemini AI
- **Readable Summaries**: Human-friendly summaries up to 200 characters
- **Exact Compatibility**: Same JSON block format as llm-analyzer-python
- **Gemini 2.5 Flash**: High-performance AI model with better availability

### **üìä Database Integration**
- **Consolidated Schema**: Works with your existing database structure
- **Status Tracking**: Clear status progression (pending ‚Üí analyzing ‚Üí completed)
- **Error Recovery**: Graceful failure handling with status updates
- **Optional Fields**: Handles missing database fields safely

## üîß **Setup & Installation**

### **1. Environment Variables**
```bash
# Required
GEMINI_API_KEY=your_gemini_api_key
BROWSERLESS_API_KEY=your_browserless_api_key  # Optional but recommended
DATABASE_ID=docify_db
DOCUMENTS_COLLECTION_ID=documents_table
APPWRITE_FUNCTION_API_ENDPOINT=https://cloud.appwrite.io/v1
APPWRITE_FUNCTION_PROJECT_ID=your_project_id

# Database field sizes (matches your current schema)
SCRAPED_CONTENT_MAX=99999    # Your current scraped_content field size
ANALYSIS_BLOCKS_MAX=99999    # Your current analysis_blocks field size
TITLE_MAX=255               # Your current title field size
SUMMARY_MAX=2000           # Your current analysis_summary field size
```

### **2. Database Schema Compatibility**
Your function works with your existing database schema:

| Field | Our Usage | Your Size |
|-------|-----------|-----------|
| `scraped_content` | Raw browserless HTML | 99999 |
| `title` | AI-generated 2-4 words | 255 |
| `analysis_summary` | Comprehensive text (‚â§5000 chars) | 5000 |
| `analysis_blocks` | JSON blocks array | 99999 |
| `gemini_tools_used` | Simple tools list | 1000 |
| `research_context` | Research findings | 5000 |
| `status` | Processing status | - |

### **2. Install Dependencies**
```bash
cd functions/docify-unified-orchestrator
pip install -r requirements.txt
```

### **3. Replace Old Function**
```bash
# Backup your existing functions first
cp -r functions/llm-analyzer-python functions/llm-analyzer-python.backup
cp -r functions/document-scraper-python functions/document-scraper-python.backup

# Replace the main.py file
cp functions/docify-unified-orchestrator/src/main_new.py functions/docify-unified-orchestrator/src/main.py

# Deploy the new unified function
appwrite functions create \
  --functionId docify-unified-orchestrator \
  --name "Docify Unified Orchestrator v3.0" \
  --runtime python-3.9 \
  --entrypoint "src/main.py" \
  --events "databases.docify_db.collections.documents_table.documents.*.create"

appwrite functions deploy --functionId docify-unified-orchestrator
```

## üéØ **How the Simplified Process Works**

### **8-Step Linear Process**

#### **Step 1: Extract Document Data**
```python
# Get document info from Appwrite trigger
document_data = extract_document_data(context)
# Returns: {'document_id': 'xxx', 'url': 'https://...', 'instructions': '...'}
```

#### **Step 2: Validate Environment**
```python
# Check API keys and setup
validate_environment()  # Ensures GEMINI_API_KEY exists
```

#### **Step 3: Raw Browserless Scraping**
```python
# Scrape content without any cleaning/modification
raw_html = scrape_raw_content(url)
# Returns: Raw HTML exactly as received from browserless
```

#### **Step 4: Save Raw Content**
```python
# Save raw HTML to database immediately
save_raw_content(document_id, raw_html)
# Updates status to 'analyzing'
```

#### **Step 5: Generate AI Title**
```python
# Generate 2-4 word title using Gemini
ai_title = generate_ai_title(url, raw_html, instructions)
# Returns: "API Documentation Guide" (2-4 words)
```

#### **Step 6: Create Analysis**
```python
# Use exact same prompt as llm-analyzer-python
analysis = generate_analysis(url, raw_html, instructions, ai_title)
# Returns: {'summary': '...', 'blocks': [...]}
```

#### **Step 7: Format Compatible Blocks**
```python
# Format blocks in exact same JSON structure
blocks_json = create_compatible_blocks(analysis)
# Returns: JSON string compatible with your docify-website
```

#### **Step 8: Final Save & Complete**
```python
# Save all results and mark as completed
final_save_and_complete(document_id, ai_title, analysis, blocks_json)
# Updates: title, analysis_summary, analysis_blocks, status='completed'
```

## üìä **Analysis Block Types**

| Type | Description | Use Case | Format Requirements |
|------|-------------|----------|-------------------|
| **summary** | Comprehensive overview | Main document summary | Plain text |
| **key_points** | Important highlights | Critical information | **Title** ***Content*** |
| **architecture** | System structure | Technical architecture | Plain text |
| **mermaid** | Visual diagrams | Flowcharts, system diagrams | Valid Mermaid.js syntax |
| **code** | Code examples | Implementation examples | Language in metadata |
| **api_reference** | API documentation | API specifications | Plain text |
| **guide** | Step-by-step instructions | Tutorials, guides | Plain text |
| **comparison** | Feature comparisons | Alternative approaches | Plain text |
| **best_practices** | Recommendations | Guidelines, tips | Plain text |
| **troubleshooting** | Common issues | Problem solutions | Plain text |

### **üìù Key Points Format**
Key points blocks must follow this exact format:
```
**Key Point Title** ***Detailed explanation of the key point***
```

**Example:**
```
**API Authentication** ***The system uses OAuth 2.0 for secure API access with JWT tokens***
**Rate Limiting** ***Requests are limited to 1000 per hour to prevent abuse***
```

## ‚úÖ **Database Schema Compatibility**

Your function works perfectly with your current database:

### **Field Mapping**
- ‚úÖ `scraped_content` (99999 chars) ‚Üê Raw browserless HTML
- ‚úÖ `title` (255 chars) ‚Üê AI-generated 2-4 word title
- ‚úÖ `status` ‚Üê Processing status tracking
- ‚úÖ `analysis_summary` (5000 chars) ‚Üê Comprehensive summary (‚â§5000 chars)
- ‚úÖ `analysis_blocks` (99999 chars) ‚Üê JSON blocks (llm-analyzer-python format)
- ‚úÖ `gemini_tools_used` (1000 chars) ‚Üê Simple tools list
- ‚úÖ `research_context` (5000 chars) ‚Üê Research findings

### **Status Flow**
```
pending ‚Üí scraping ‚Üí analyzing ‚Üí completed
   ‚Üì         ‚Üì         ‚Üì         ‚Üì
Created  Scraping  Analyzing  Ready
```

## üß™ **Testing**

### **Quick Test**
```python
# Test the function locally
python src/main_new.py
```

### **Expected Output**
```
üöÄ Docify Unified Orchestrator v3.0 loaded successfully
‚ú® Features: Raw content preservation, AI titles, compatible blocks
üîí Safe approach: No content cleaning/modification
ü§ñ AI-powered: 2-4 word titles, readable summaries
üîó Compatible: Same JSON format as existing analyzer
```

## üéØ **Success Criteria**

‚úÖ **Raw Content Preserved**: `scraped_content` contains exact browserless HTML
‚úÖ **AI Titles Generated**: `title` field has 2-4 word AI-generated title
‚úÖ **Readable Summaries**: `analysis_summary` is human-readable text ‚â§200 chars
‚úÖ **Compatible Blocks**: `analysis_blocks` matches llm-analyzer-python JSON format
‚úÖ **Status Tracking**: Clear progression through all status states
‚úÖ **Error Recovery**: Graceful failure handling with status updates

## üöÄ **Deployment Ready**

Your new simplified unified orchestrator is ready for deployment:

1. ‚úÖ **Environment configured** - Uses your existing GEMINI_API_KEY
2. ‚úÖ **Database compatible** - Works with your current schema
3. ‚úÖ **Website compatible** - Same JSON format as llm-analyzer-python
4. ‚úÖ **Safe approach** - No dangerous content cleaning
5. ‚úÖ **Simple process** - 8 clear steps instead of 50+ complex methods

**Ready to deploy and replace your old functions!** üéâ
